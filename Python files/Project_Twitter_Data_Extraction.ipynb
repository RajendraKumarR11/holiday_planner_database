{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\nCONCLUSIONS:\\n\\nThis code uses the list of cities, selected for the project and  tries to find the popularity parameters related \\nto the same through Twitter API, stores the results in dataframe and exports it to a CSV file.\\n\\nCONTRIBUTIONS:\\n\\nRAJENDRA KUMAR RAJKUMAR - 75% \\nMONISH  HIRISAVE RAGHU - 25%\\n\\nCITATIONS:\\n\\n1. https://www.geeksforgeeks.org\\n2. https://github.com/nikbearbrown/INFO_6210\\n\\nThe code with regard to extraction of information from twitter was used from the above mentioned resources\\n\\nOriginal writtten code - 60%\\nCode referenced from external sources(but modified suiting needs) - 40%\\n\\nLICENSE:\\n\\nCopyright <2019> <RAJENDRA KUMAR RAJKUMAR, MONISH  HIRISAVE RAGHU>\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\\n\\n\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Web_API_Extraction from Twitter\n",
    "# This class containes the code for extracting popularity information related to cities through Twitter API.\n",
    "# Detailed description availble through inline comments.\n",
    "\n",
    "import twitter# pip install twitter\n",
    "import json \n",
    "import pandas as pd\n",
    "from urllib.parse import unquote\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "# Storing relevant keys and token information in desired variables\n",
    "consumer_key = \"8kN7ITYYYK6bNkHKoViRPb7gJ\"\n",
    "consumer_secret = \"g8IGSzKWckrYRzYjTgm8J2oNIywsmzcS8I9zW6WTrtIx28RGrE\"\n",
    "access_token = \"1088871960698908674-WsDWHHSB2jcaH9zMwaW5mNgpwIzpGM\"\n",
    "access_token_secret = \"0pHfCkkkjEhWeQbm6tZ9eWHRLXzIh4dyNimAHXmuvYg6j\"\n",
    "\n",
    "\n",
    "\n",
    "# Initialising twitter api\n",
    "api = twitter.Api(consumer_key=consumer_key,\n",
    "                  consumer_secret=consumer_secret,\n",
    "                  access_token_key=access_token,\n",
    "                  access_token_secret=access_token_secret)\n",
    "\n",
    "\n",
    "\n",
    "# Reading the data extracted from kaggel, which contains the list of players, whose popularity information is what is \n",
    "# going to be extracted from twitter \n",
    "cities_input = pd.read_csv('City.csv')\n",
    "#Constructing a dictionary from two columns of the read data namely 'Player_ID' and 'Player_Name' adn stored in cricket_players_dict\n",
    "cities_dict= dict(zip(cities_input.city_id, cities_input.city_name))\n",
    "\n",
    "# Initialising below empty lists for storing player popularity related information\n",
    "city_id_list = []\n",
    "tweet_content_list = []\n",
    "tweet_datetime_list = []\n",
    "favourite_count_list = []\n",
    "retweet_count_list = []\n",
    "user_id_list = []\n",
    "tweet_id_list = []\n",
    "user_name_list = []\n",
    "user_screen_name_list = []\n",
    "user_followers_count_list = []\n",
    "hashtag_tweet_id_list = []\n",
    "hashtag_content_list = []\n",
    "hashtag_id_list = []\n",
    "\n",
    "\n",
    "#Iterating through the items of dictionary 'cities_dict'\n",
    "for key, value in cities_dict.items():\n",
    "\n",
    "        \n",
    "    # Searching using city name as inout\n",
    "    results = api.GetSearch(raw_query=\"q=\" +value+ \"&count=5\")\n",
    "    cnt = len(results)\n",
    "    \n",
    "    \n",
    "    #Iterating through the results\n",
    "    for res in results:\n",
    "        x = json.loads(str(res))\n",
    "        hashtags_used = []\n",
    "        \n",
    "        # Considering only tweets in English Language\n",
    "        if x['lang']=='en':      \n",
    "            # Storing the 'key'(cityid) in city_id_list\n",
    "            city_id_list.append(key)\n",
    "            # Storing the actual text of the tweet in tweet_content_list\n",
    "            tweet_content_list.append(x['text'])\n",
    "            # Converting the date into readable formate and storing in tweet_datetime_list\n",
    "            tweet_datetime_list.append(time.strftime('%Y-%m-%d %H:%M:%S', time.strptime(x['created_at'],'%a %b %d %H:%M:%S +0000 %Y')))\n",
    "            favourite_count = 0\n",
    "            # IF there is an exception while accessing 'Favorite_count', then 'favorite_count' from 'retweeted_status' is used\n",
    "            try:\n",
    "                try:\n",
    "                    favourite_count = x['favorite_count']\n",
    "                except:\n",
    "                    favourite_count = x['retweeted_status']['favorite_count']\n",
    "            except:\n",
    "                 favourite_count = 0   \n",
    "            favourite_count_list.append(favourite_count)\n",
    "            \n",
    "            # If there is an exception with accesing 'retweet_count', then 0 is stored\n",
    "            try:\n",
    "                retweet_count_list.append(x['retweet_count'])\n",
    "            except:\n",
    "                retweet_count_list.append(0)\n",
    "                \n",
    "            # String version of userid and tweetid are stored in user_id_list and tweet_id_list\n",
    "            user_id_list.append(x['user']['id_str'])\n",
    "            tweet_id_list.append(x['id_str'])\n",
    "            \n",
    "            # 'User name' and 'User Screen name' are stored in user_name_list and user_screen_name_list respectively\n",
    "            user_name_list.append(x['user']['name'])\n",
    "            user_screen_name_list.append(x['user']['screen_name'])\n",
    "            \n",
    "            # If there is an exception with accessing user's followers_count, then 0 is stored\n",
    "            try:\n",
    "                user_followers_count_list.append(x['user']['followers_count'])\n",
    "            except:\n",
    "                user_followers_count_list.append(0)\n",
    "            \n",
    "            # If there is an exception with accessing first hashtag's text, then entire information from hashtags are stored\n",
    "            try:\n",
    "                hashtags_used.append(x['hashtags'][0]['text'])\n",
    "            except:\n",
    "                hashtags_used.append(x['hashtags'])\n",
    "            \n",
    "           # Empty lists which were stored in 'hashtags_used' list are removed and the corrected version is stored in \n",
    "           # hashtags_used_corrected\n",
    "            hashtags_used_empty_lists_removed = [x for x in hashtags_used if x != []]\n",
    "            hashtags_used_corrected = [x for x in hashtags_used_empty_lists_removed if x]    \n",
    "            \n",
    "            #Iterating through list of all retrieved and stored hashtags\n",
    "            for hashtag in hashtags_used_corrected:\n",
    "                \n",
    "                # Storign the respective hashtag information in relevant lists \n",
    "                # Storing the string version of hashtag tweed id in hashtag_tweet_id_list\n",
    "                hashtag_tweet_id_list.append(x['id_str'])\n",
    "                hashtag_content_list.append(hashtag)\n",
    "                # Hashtag id is created by concatenating hahstag id and string version of the entire hashtag\n",
    "                hashtag_id_list.append(x['id_str'] + str(hashtag))\n",
    "                \n",
    "                \n",
    "                \n",
    "# Creating a dataframe city_tweet_df to store tweet information collected with regard to cities         \n",
    "city_tweet_df = pd.DataFrame(data = city_id_list, columns = ['city_id'])\n",
    "city_tweet_df['Content'] = tweet_content_list  \n",
    "city_tweet_df['Created_Time'] = tweet_datetime_list\n",
    "city_tweet_df['Favourite_Count'] = favourite_count_list\n",
    "city_tweet_df['Retweet_Count'] = retweet_count_list\n",
    "city_tweet_df['Tweet_ID'] = tweet_id_list\n",
    "city_tweet_df['User_ID'] = user_id_list\n",
    "\n",
    "\n",
    "# Rename column 'city_id' to 'City_ID'\n",
    "city_tweet_df = city_tweet_df.rename(columns={'city_id': 'City_ID'})\n",
    "\n",
    "\n",
    "# Creating a dataframe city_twitter_user_df to store information about user, who had posted tweets collected with regard to cities           \n",
    "city_twitter_user_df = pd.DataFrame(data = user_id_list , columns = ['User_ID'])\n",
    "city_twitter_user_df['User_Name'] = user_name_list\n",
    "city_twitter_user_df['User_Screen_Name'] = user_screen_name_list\n",
    "city_twitter_user_df['Followers_Count'] = user_followers_count_list\n",
    "\n",
    "\n",
    "# Creating a dataframe city_twitter_hashtag_df  to store information about hashtags which were used in tweets collected with regard to cities           \n",
    "city_twitter_hashtag_df = pd.DataFrame(data = hashtag_tweet_id_list , columns = ['Tweet_ID'])\n",
    "city_twitter_hashtag_df ['Name'] = hashtag_content_list\n",
    "city_twitter_hashtag_df ['Hashtag_ID'] = hashtag_id_list\n",
    "\n",
    "\n",
    "\n",
    "# Removal of duplicate rows with regard to 'Tweet_ID', 'User_ID' and 'Hashtag_ID' fields in the below dataframes \n",
    "city_tweet_df.drop_duplicates(subset=['Tweet_ID'], keep='first', inplace= True)\n",
    "city_twitter_user_df.drop_duplicates(subset=['User_ID'], keep='first', inplace= True)\n",
    "city_twitter_hashtag_df.drop_duplicates(subset=['Hashtag_ID'], keep='first', inplace= True)\n",
    "\n",
    "# Exporting dataframes to respective csv files\n",
    "city_tweet_df.to_csv(\"City_Twitter_Extracted_Tweet.csv\", index=False)\n",
    "city_twitter_user_df.to_csv(\"City_Twitter_Extracted_TwitterUser.csv\",index=False)\n",
    "city_twitter_hashtag_df.to_csv(\"City_Twitter_Extracted_TwitterHashtag.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\"\n",
    "CONCLUSIONS:\n",
    "\n",
    "This code uses the list of cities, selected for the project and  tries to find the popularity parameters related \n",
    "to the same through Twitter API, stores the results in dataframe and exports it to a CSV file.\n",
    "\n",
    "CONTRIBUTIONS:\n",
    "\n",
    "RAJENDRA KUMAR RAJKUMAR - 75% \n",
    "MONISH  HIRISAVE RAGHU - 25%\n",
    "\n",
    "CITATIONS:\n",
    "\n",
    "1. https://www.geeksforgeeks.org\n",
    "2. https://github.com/nikbearbrown/INFO_6210\n",
    "\n",
    "The code with regard to extraction of information from twitter was used from the above mentioned resources\n",
    "\n",
    "Original writtten code - 60%\n",
    "Code referenced from external sources(but modified suiting needs) - 40%\n",
    "\n",
    "LICENSE:\n",
    "\n",
    "Copyright <2019> <RAJENDRA KUMAR RAJKUMAR, MONISH  HIRISAVE RAGHU>\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Api' object has no attribute 'trends'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-8a1238355c40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#        print(\" - %s\" % trend[\"name\"])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrends\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Api' object has no attribute 'trends'"
     ]
    }
   ],
   "source": [
    "#results = api.trends.place(_id = 23424975)\n",
    "\n",
    "#print(\"UK Trends\")\n",
    "\n",
    "#for location in results:\n",
    "#    for trend in location[\"trends\"]:\n",
    "#        print(\" - %s\" % trend[\"name\"])\n",
    "        \n",
    "print(api.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
